#!/usr/bin/env python

# Copyright (C) 2013 Craig Phillips.  All rights reserved.

import sys, os, logging, re
from libgsync.options import GsyncOptions
from libgsync.output import verbose, debug
from libgsync.crawler import Crawler
from libgsync.filter import Filter

if GsyncOptions.verbose:
    verbose.enable()

if GsyncOptions.debug:
    debug.enable()

if not GsyncOptions.super and os.getuid() != 0:
    if GsyncOptions.owner or GsyncOptions.group:
        print("Warning: Not running as root, file ownership may be ignored")

logging.basicConfig()
paths = GsyncOptions.list().source_paths
dest = GsyncOptions.destination_path

debug(GsyncOptions.options)

if GsyncOptions.filter is not None:
    Filter.addRules(GsyncOptions.list().filter)

if GsyncOptions.include_from is not None:
    Filter.loadRules(GsyncOptions.list().include_from, "+")

if GsyncOptions.include is not None:
    Filter.addRules(GsyncOptions.list().include, "+")

if GsyncOptions.exclude_from is not None:
    Filter.loadRules(GsyncOptions.list().exclude_from, "-")

if GsyncOptions.exclude is not None:
    Filter.addRules(GsyncOptions.list().exclude, "-")

# If there are multiple source paths, the destination is always a
# directory if a name is supplied.  Otherwise, the destination is
# a directory if the source is also a directory, or it is a file if
# the destination does not exist or is already an existing file.
if len(paths) > 1:
    debug("Multiple source files, destination cannot be a file")
    GsyncOptions.force_dest_file = False
else:
    GsyncOptions.force_dest_file = None

try:
    for p in paths:
        debug("Creating crawler for: %s" % repr(p))
        crawler = Crawler(p, dest)
        crawler.run()

except KeyboardInterrupt, e:
    sys.exit(1)

except Exception, e:
    debug.exception(e)
    sys.stderr.write("Error: %s\n" % str(e))
    sys.exit(255)

debug("Crawlers finished, exiting")

sys.exit(0)
